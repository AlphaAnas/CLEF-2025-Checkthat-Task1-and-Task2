{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e8058527bfb48b1ae2c9e029f05d289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5a5da7a9ee64910a736cce4d403cbfc",
              "IPY_MODEL_0baea48fe94847b6a18ad93813f71595",
              "IPY_MODEL_ab51e0c0780547878fa82bfb022a115b"
            ],
            "layout": "IPY_MODEL_1dde81114662403692cb1367679cb4b0"
          }
        },
        "b5a5da7a9ee64910a736cce4d403cbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a10e37125644d688f6066f28370ca59",
            "placeholder": "​",
            "style": "IPY_MODEL_f5ffff70f3ff4e99b868039baa6838d1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0baea48fe94847b6a18ad93813f71595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b732679b15b49f3a5f1fdf6ffba98ff",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76500758050f4a64b4d3600e3a6ff978",
            "value": 412
          }
        },
        "ab51e0c0780547878fa82bfb022a115b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ec2c31302c43b4948d2bdef795240b",
            "placeholder": "​",
            "style": "IPY_MODEL_159e4856f53049859726eafdb320fdc5",
            "value": " 412/412 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "1dde81114662403692cb1367679cb4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a10e37125644d688f6066f28370ca59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ffff70f3ff4e99b868039baa6838d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b732679b15b49f3a5f1fdf6ffba98ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76500758050f4a64b4d3600e3a6ff978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2ec2c31302c43b4948d2bdef795240b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "159e4856f53049859726eafdb320fdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3009f5b0d57847d0a8c3535d5e79b725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7ec28e0c3b54c1195f34e6166912732",
              "IPY_MODEL_3501c5bf710742cc911275ba17aa0fdf",
              "IPY_MODEL_63691d12aa264e07934a8d179d2ea013"
            ],
            "layout": "IPY_MODEL_01be82b95fdd4732a6e62473c3562a18"
          }
        },
        "e7ec28e0c3b54c1195f34e6166912732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f84e8de73f42a4997a5a1e4a791c39",
            "placeholder": "​",
            "style": "IPY_MODEL_ef17c62b7ef042c6a9ab015d9d38570d",
            "value": "spm.model: 100%"
          }
        },
        "3501c5bf710742cc911275ba17aa0fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e1492a16bd4aa5bfe0dc6342b5980a",
            "max": 4305025,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9a341b156bc4670aa4312784ef8dbe8",
            "value": 4305025
          }
        },
        "63691d12aa264e07934a8d179d2ea013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cadd21488f484883b9f5e8fec4bcb1c3",
            "placeholder": "​",
            "style": "IPY_MODEL_192da315f59b4b05acb9fab8c344bbdc",
            "value": " 4.31M/4.31M [00:00&lt;00:00, 38.7MB/s]"
          }
        },
        "01be82b95fdd4732a6e62473c3562a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f84e8de73f42a4997a5a1e4a791c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef17c62b7ef042c6a9ab015d9d38570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69e1492a16bd4aa5bfe0dc6342b5980a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a341b156bc4670aa4312784ef8dbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cadd21488f484883b9f5e8fec4bcb1c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192da315f59b4b05acb9fab8c344bbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30ee32c158134dcbb2e6dbcaff99fd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51720de1de5e4bcaa5fc7c92a115ace8",
              "IPY_MODEL_9867611161214c59b0df16fb224af2c5",
              "IPY_MODEL_41509aa7a993401ab70a9fd2861efd77"
            ],
            "layout": "IPY_MODEL_c91915a6d00c4de19cffc8c02c754218"
          }
        },
        "51720de1de5e4bcaa5fc7c92a115ace8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bfd1c24c2834ee7aaf9b1cdde50b335",
            "placeholder": "​",
            "style": "IPY_MODEL_b40215f1604b496db36e0cd3debdd85e",
            "value": "tokenizer.json: 100%"
          }
        },
        "9867611161214c59b0df16fb224af2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ecdd626f77f466291f4c6eef48e2464",
            "max": 16331564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b472b38d8454095be5a7497eb6ec344",
            "value": 16331564
          }
        },
        "41509aa7a993401ab70a9fd2861efd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbce2343f6d54b30bf45d401c6e24624",
            "placeholder": "​",
            "style": "IPY_MODEL_c30181874a834f79bddf4182bd92c966",
            "value": " 16.3M/16.3M [00:00&lt;00:00, 155MB/s]"
          }
        },
        "c91915a6d00c4de19cffc8c02c754218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfd1c24c2834ee7aaf9b1cdde50b335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40215f1604b496db36e0cd3debdd85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ecdd626f77f466291f4c6eef48e2464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b472b38d8454095be5a7497eb6ec344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbce2343f6d54b30bf45d401c6e24624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30181874a834f79bddf4182bd92c966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b95ad0ceae5490db4e5fba1ea757613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02c9a4d02e6f46d8a6340803cf4b2ad7",
              "IPY_MODEL_a72205ee67684ad9a67839b16871bd1d",
              "IPY_MODEL_b16bf220fd9b4d799cc35c12250e8551"
            ],
            "layout": "IPY_MODEL_73a00d53a0aa4ad99af1b715e640aaa0"
          }
        },
        "02c9a4d02e6f46d8a6340803cf4b2ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a4cc6705ca4ca6b5077adaa7acff5f",
            "placeholder": "​",
            "style": "IPY_MODEL_3a9b21bb7e9349868c5050801561246e",
            "value": "added_tokens.json: 100%"
          }
        },
        "a72205ee67684ad9a67839b16871bd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cd77e2e0444890a60165d4792f09ac",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73e4e08b3e0549e6935ae75db4dc0151",
            "value": 23
          }
        },
        "b16bf220fd9b4d799cc35c12250e8551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a93821f7834e2fa1e13b027fd3cc26",
            "placeholder": "​",
            "style": "IPY_MODEL_8d0bcc8b74a04a25aa22d68ac9ed8dfa",
            "value": " 23.0/23.0 [00:00&lt;00:00, 1.08kB/s]"
          }
        },
        "73a00d53a0aa4ad99af1b715e640aaa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a4cc6705ca4ca6b5077adaa7acff5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9b21bb7e9349868c5050801561246e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7cd77e2e0444890a60165d4792f09ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e4e08b3e0549e6935ae75db4dc0151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19a93821f7834e2fa1e13b027fd3cc26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0bcc8b74a04a25aa22d68ac9ed8dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58b3608e5662475dbceb276b4431e4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c7483c1881142c79af6e04ec081628f",
              "IPY_MODEL_a20fe7923dc245ac8ee202b07bcddf0a",
              "IPY_MODEL_a7762fbe39614ea598e60445435c2155"
            ],
            "layout": "IPY_MODEL_61924113455c4205a3e90b020bb76ab3"
          }
        },
        "2c7483c1881142c79af6e04ec081628f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b66a11ddc14257a9f54b2a2de91a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_e7efd86b94a446e890a23bd008e0b95f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a20fe7923dc245ac8ee202b07bcddf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32bff2df40634429b32ca58ca32498a6",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd356c67de39415f91ac41377976a4bd",
            "value": 173
          }
        },
        "a7762fbe39614ea598e60445435c2155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20100cf0f31d46ecb04ddcaffca40655",
            "placeholder": "​",
            "style": "IPY_MODEL_739577decd024e92a5208e3b854312cf",
            "value": " 173/173 [00:00&lt;00:00, 9.91kB/s]"
          }
        },
        "61924113455c4205a3e90b020bb76ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b66a11ddc14257a9f54b2a2de91a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7efd86b94a446e890a23bd008e0b95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32bff2df40634429b32ca58ca32498a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd356c67de39415f91ac41377976a4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20100cf0f31d46ecb04ddcaffca40655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "739577decd024e92a5208e3b854312cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVOcsPHZ-fcv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMdKQPlfOqp0",
        "outputId": "3896cfea-575b-4796-e554-35241a474fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzwLyRe9Ottb",
        "outputId": "1ca97ade-afe4-4524-8bc0-6ac60928baa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Set up constants\n",
        "MODEL_NAME_ = \"GroNLP/mdebertav3-subjectivity-multilingual\"\n",
        "# MODEL_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 3e-5"
      ],
      "metadata": {
        "id": "dQCBR5GE-qsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22df1XCkIkQa",
        "outputId": "8dfd733e-2b7c-4720-ba1f-79a56f209024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "save_dir = '/content/drive/MyDrive/saved_model'\n",
        "# Load from the same path\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "\n",
        "# Move model to correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"✅ Model and tokenizer successfully loaded from Drive\")\n"
      ],
      "metadata": {
        "id": "C4amNusdLpWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "def load_data(file_list, source_dir='/content/drive/MyDrive/data', target_dir='/content'):\n",
        "    \"\"\"\n",
        "    Load TSV files from Google Drive and save them to a local directory in Colab.\n",
        "    Each language has its own folder in the data directory.\n",
        "\n",
        "    Args:\n",
        "        file_list (list): List of TSV filenames to load (e.g., 'train_ar.tsv')\n",
        "        source_dir (str): Base source directory in Google Drive\n",
        "        target_dir (str): Target directory in Colab workspace\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of pandas DataFrames with filename as key\n",
        "    \"\"\"\n",
        "    # Create target directory if it doesn't exist\n",
        "    data_dir = os.path.join(target_dir, 'data')\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "        print(f\"Created directory: {data_dir}\")\n",
        "\n",
        "    # Dictionary to store dataframes\n",
        "    dataframes = {}\n",
        "\n",
        "    # Language mapping from filename prefixes\n",
        "    language_map = {\n",
        "        'ar': 'arabic',\n",
        "        'bg': 'bulgarian',\n",
        "        'de': 'german',\n",
        "        'en': 'english',\n",
        "        'it': 'italian'\n",
        "    }\n",
        "\n",
        "    # Process each file in the list\n",
        "    for filename in file_list:\n",
        "        # Extract language code from filename (e.g., 'ar' from 'train_ar.tsv')\n",
        "        # Format could be 'train_ar.tsv' or 'dev_ar.tsv' or 'arabic_train_augmented.tsv'\n",
        "        if filename.startswith('train_') or filename.startswith('dev_'):\n",
        "            lang_code = filename.split('_')[1].split('.')[0]\n",
        "            language_folder = language_map.get(lang_code, lang_code)\n",
        "        elif '_train_augmented' in filename:\n",
        "            # Handle augmented filenames like 'arabic_train_augmented.tsv'\n",
        "            language_folder = filename.split('_')[0]\n",
        "        elif \"_unlabeled\" in filename:\n",
        "            # Handle unlabeled filenames like 'test_ar_unlabeled.tsv\n",
        "            lang_code = filename.split('_')[1]\n",
        "            language_folder = language_map.get(lang_code, lang_code)\n",
        "        else:\n",
        "            # If format is unknown, just use the filename as is\n",
        "            language_folder = filename.split('.')[0]\n",
        "\n",
        "        # Create language folder in target directory if it doesn't exist\n",
        "        lang_target_dir = os.path.join(data_dir, language_folder)\n",
        "        if not os.path.exists(lang_target_dir):\n",
        "            os.makedirs(lang_target_dir)\n",
        "            print(f\"Created directory: {lang_target_dir}\")\n",
        "\n",
        "        # Check for source file in the language-specific folder\n",
        "        source_path = os.path.join(source_dir, language_folder, filename)\n",
        "        target_path = os.path.join(lang_target_dir, filename)\n",
        "\n",
        "        # Check if source file exists\n",
        "        if os.path.exists(source_path):\n",
        "            try:\n",
        "                # Read the TSV file\n",
        "                df = pd.read_csv(source_path, sep='\\t')\n",
        "                dataframes[filename] = df\n",
        "\n",
        "                # Save to target location\n",
        "                df.to_csv(target_path, sep='\\t', index=False)\n",
        "                print(f\"✅ Successfully loaded and copied {filename} from {language_folder} folder\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error processing {filename} from {language_folder} folder: {e}\")\n",
        "        else:\n",
        "            print(f\"❌ Source file not found: {source_path}\")\n",
        "\n",
        "    return dataframes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQFBF9WLNynY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_augmented_data(train_dataframes, data_dir='/content/data'):\n",
        "    \"\"\"\n",
        "    Merge augmented training data with original training data and update the original dictionary.\n",
        "\n",
        "    Args:\n",
        "        train_dataframes (dict): Dictionary of training dataframes (modifies in place)\n",
        "        data_dir (str): Directory where files should be saved\n",
        "    \"\"\"\n",
        "    augmentation_map = {\n",
        "        'train_ar.tsv': 'arabic_train_augmented.tsv',\n",
        "        'train_bg.tsv': 'bulgarian_train_augmented.tsv',\n",
        "        # Add other language pairs as needed\n",
        "    }\n",
        "\n",
        "    language_map = {\n",
        "        'train_ar.tsv': 'arabic',\n",
        "        'train_bg.tsv': 'bulgarian',\n",
        "        'train_de.tsv': 'german',\n",
        "        'train_en.tsv': 'english',\n",
        "        'train_it.tsv': 'italian'\n",
        "    }\n",
        "\n",
        "    for train_file, augmented_file in augmentation_map.items():\n",
        "        if train_file in train_dataframes and augmented_file in train_dataframes:\n",
        "            print(f\"Merging {augmented_file} into {train_file}...\")\n",
        "\n",
        "            combined_df = pd.concat(\n",
        "                [train_dataframes[train_file], train_dataframes[augmented_file]],\n",
        "                ignore_index=True\n",
        "            )\n",
        "\n",
        "            # ✅ Overwrite the entry in the dictionary\n",
        "            train_dataframes[train_file] = combined_df\n",
        "\n",
        "            # Save the new combined file\n",
        "            language_folder = language_map.get(train_file, train_file.split('_')[1].split('.')[0])\n",
        "            output_path = os.path.join(data_dir, language_folder, train_file)\n",
        "            combined_df.to_csv(output_path, sep='\\t', index=False)\n",
        "\n",
        "            print(f\"✅ Successfully merged and saved {train_file}\")\n",
        "            print(f\"   📏 Length after merge: {len(combined_df)}\")\n"
      ],
      "metadata": {
        "id": "dC-MsZiMQnY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define file lists\n",
        "train_files = [\n",
        "    'train_ar.tsv',\n",
        "    'train_bg.tsv',\n",
        "    'train_de.tsv',\n",
        "    'train_en.tsv',\n",
        "    'train_it.tsv'\n",
        "]\n",
        "\n",
        "validation_files = [\n",
        "    'dev_ar.tsv',\n",
        "    'dev_bg.tsv',\n",
        "    'dev_de.tsv',\n",
        "    'dev_en.tsv',\n",
        "    'dev_it.tsv'\n",
        "]\n",
        "\n",
        "# Also include augmented files if they exist\n",
        "augmented_files = [\n",
        "    'arabic_train_augmented.tsv',\n",
        "    'bulgarian_train_augmented.tsv'\n",
        "]\n",
        "\n",
        "\n",
        "# Load all files\n",
        "all_files = train_files + validation_files + augmented_files\n",
        "data_folder = '/content/drive/MyDrive/data'\n",
        "all_dataframes = load_data(all_files, source_dir=data_folder)\n",
        "\n",
        "# Merge augmented data with original training data\n",
        "merge_augmented_data(all_dataframes)\n",
        "\n",
        "# Now you can access the training and validation data separately\n",
        "train_dataframes = {filename: all_dataframes[filename] for filename in train_files if filename in all_dataframes}\n",
        "val_dataframes = {filename: all_dataframes[filename] for filename in validation_files if filename in all_dataframes}\n",
        "\n",
        "\n",
        "print(\"✅ All data processing complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKNaXcFmQqUV",
        "outputId": "c6f59730-feb1-4c60-ddaa-a5fb741def58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: /content/data\n",
            "Created directory: /content/data/arabic\n",
            "✅ Successfully loaded and copied train_ar.tsv from arabic folder\n",
            "Created directory: /content/data/bulgarian\n",
            "✅ Successfully loaded and copied train_bg.tsv from bulgarian folder\n",
            "Created directory: /content/data/german\n",
            "✅ Successfully loaded and copied train_de.tsv from german folder\n",
            "Created directory: /content/data/english\n",
            "✅ Successfully loaded and copied train_en.tsv from english folder\n",
            "Created directory: /content/data/italian\n",
            "✅ Successfully loaded and copied train_it.tsv from italian folder\n",
            "✅ Successfully loaded and copied dev_ar.tsv from arabic folder\n",
            "✅ Successfully loaded and copied dev_bg.tsv from bulgarian folder\n",
            "✅ Successfully loaded and copied dev_de.tsv from german folder\n",
            "✅ Successfully loaded and copied dev_en.tsv from english folder\n",
            "✅ Successfully loaded and copied dev_it.tsv from italian folder\n",
            "✅ Successfully loaded and copied arabic_train_augmented.tsv from arabic folder\n",
            "✅ Successfully loaded and copied bulgarian_train_augmented.tsv from bulgarian folder\n",
            "Merging arabic_train_augmented.tsv into train_ar.tsv...\n",
            "✅ Successfully merged and saved train_ar.tsv\n",
            "   📏 Length after merge: 3721\n",
            "Merging bulgarian_train_augmented.tsv into train_bg.tsv...\n",
            "✅ Successfully merged and saved train_bg.tsv\n",
            "   📏 Length after merge: 1962\n",
            "✅ All data processing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = {filename: all_dataframes[filename] for filename in train_files if filename in all_dataframes}\n",
        "for fname, df in train_files.items():\n",
        "    print(f\"{fname}: {df.shape}\")\n",
        "    print(df.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2eXj9T--CQf",
        "outputId": "47adb260-bbe7-4490-c05c-2884d1907619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ar.tsv: (3721, 3)\n",
            "          sentence_id                                           sentence label\n",
            "0  AlMasryAlYoum_10_1  عندما تولى الرئيس عبد الفتاح السيسى السلطة فى ...   OBJ\n",
            "1  MAH_62-curl_01_005  في هذا السياق يشرح عيراني أنّ الخوف لا يقتصر ف...   OBJ\n",
            "train_bg.tsv: (1962, 3)\n",
            "                            sentence_id  \\\n",
            "0  b678f74b-3981-4ad9-93b3-4c549605a02c   \n",
            "1  ea65624a-da34-4bc4-8085-edb93d2e30e1   \n",
            "\n",
            "                                            sentence label  \n",
            "0  Учителите, за които цяла България разбра, са С...   OBJ  \n",
            "1               А ако намерите каска е още по-добре.  SUBJ  \n",
            "train_de.tsv: (800, 3)\n",
            "                                sentence_id  \\\n",
            "0  4f9c8bcd60318b0d1257f35ebc7c4ede9f7930e1   \n",
            "1  0531b165e42997e8eecbb84d1e774c728041db8c   \n",
            "\n",
            "                                            sentence label  \n",
            "0  Die Ausbreitung des Virus sei beschränkter als...   OBJ  \n",
            "1    Zwar sei ein Anstieg der Zahlen zu verzeichnen.   OBJ  \n",
            "train_en.tsv: (830, 4)\n",
            "                            sentence_id  \\\n",
            "0  b9e1635a-72aa-467f-86d6-f56ef09f62c3   \n",
            "1  f99b5143-70d2-494a-a2f5-c68f10d09d0a   \n",
            "\n",
            "                                            sentence label  solved_conflict  \n",
            "0  Gone are the days when they led the world in r...  SUBJ             True  \n",
            "1  The trend is expected to reverse as soon as ne...   OBJ            False  \n",
            "train_it.tsv: (1613, 3)\n",
            "                            sentence_id  \\\n",
            "0  09b67800-c9c1-4dd4-a970-90c12db8a401   \n",
            "1  38b16d4c-9a2e-4add-8833-e4e376a389d7   \n",
            "\n",
            "                                            sentence label  \n",
            "0  La donna aveva una bandiera pro Trump e dopo e...   OBJ  \n",
            "1  Quando questi bisogni vengono minacciati allor...  SUBJ  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save the data from drive to colab for easier access\n"
      ],
      "metadata": {
        "id": "UkDKB0K_XAvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_local(file_names, base_dir='/content/data'):\n",
        "    \"\"\"\n",
        "    Load data from multiple TSV files in language-specific folders and combine them.\n",
        "\n",
        "    Args:\n",
        "        file_names (list): List of TSV filenames (e.g., ['train_ar.tsv', 'test_ar_unlabeled.tsv'])\n",
        "        base_dir (str): Base directory where language folders are located\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Combined dataframe with all data and language tags\n",
        "    \"\"\"\n",
        "    # Language mapping from filename prefixes to folder names\n",
        "    language_map = {\n",
        "        'ar': 'arabic',\n",
        "        'bg': 'bulgarian',\n",
        "        'de': 'german',\n",
        "        'en': 'english',\n",
        "        'it': 'italian'\n",
        "    }\n",
        "\n",
        "    dfs = []\n",
        "    for file_name in file_names:\n",
        "        # Determine language code based on known patterns\n",
        "        if '_train_augmented' in file_name:\n",
        "            lang_code = file_name.split('_')[0]  # e.g., 'arabic'\n",
        "            language_folder = lang_code\n",
        "            lang_tag = {v: k for k, v in language_map.items()}.get(lang_code, lang_code)\n",
        "        elif '_unlabeled' in file_name:\n",
        "            lang_code = file_name.split('_')[1]  # e.g., 'ar' in 'test_ar_unlabeled.tsv'\n",
        "            language_folder = language_map.get(lang_code, lang_code)\n",
        "            lang_tag = lang_code\n",
        "        elif '_' in file_name:\n",
        "            lang_code = file_name.split('_')[1].split('.')[0]\n",
        "            language_folder = language_map.get(lang_code, lang_code)\n",
        "            lang_tag = lang_code\n",
        "        else:\n",
        "            language_folder = file_name.split('.')[0]\n",
        "            lang_tag = language_folder\n",
        "\n",
        "        # Construct full file path\n",
        "        file_path = os.path.join(base_dir, language_folder, file_name)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, sep='\\t', header=0)\n",
        "\n",
        "                # Drop 'solved_conflict' column if it exists\n",
        "                if 'solved_conflict' in df.columns:\n",
        "                    df = df.drop(columns=['solved_conflict'])\n",
        "\n",
        "                # Add language tag\n",
        "                df['language'] = lang_tag\n",
        "\n",
        "                dfs.append(df)\n",
        "                print(f\"✅ Successfully loaded {file_name} from {language_folder} folder\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error reading {file_path}: {e}\")\n",
        "        else:\n",
        "            print(f\"❌ File not found: {file_path}\")\n",
        "\n",
        "    if dfs:\n",
        "        return pd.concat(dfs, ignore_index=True)\n",
        "    else:\n",
        "        print(\"No data was loaded. Returning empty DataFrame.\")\n",
        "        return pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "3Tmjvux5-sO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and validation data separately\n",
        "train_data = load_data_local(train_files)\n",
        "val_data = load_data_local(validation_files)\n",
        "\n",
        "# Convert labels to integers\n",
        "label_map = {'OBJ': 0, 'SUBJ': 1}\n",
        "train_data['label_id'] = train_data['label'].map(label_map)\n",
        "val_data['label_id'] = val_data['label'].map(label_map)\n",
        "\n",
        "# Reset indices\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "val_data = val_data.reset_index(drop=True)\n",
        "\n",
        "print(f\"Training with {len(train_data)} examples\")\n",
        "print(f\"Validating with {len(val_data)} examples\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhEx_G7R_WUz",
        "outputId": "f8b1a855-b5d0-4e49-f8f9-a178f4ad7e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully loaded train_ar.tsv from arabic folder\n",
            "✅ Successfully loaded train_bg.tsv from bulgarian folder\n",
            "✅ Successfully loaded train_de.tsv from german folder\n",
            "✅ Successfully loaded train_en.tsv from english folder\n",
            "✅ Successfully loaded train_it.tsv from italian folder\n",
            "✅ Successfully loaded dev_ar.tsv from arabic folder\n",
            "✅ Successfully loaded dev_bg.tsv from bulgarian folder\n",
            "✅ Successfully loaded dev_de.tsv from german folder\n",
            "✅ Successfully loaded dev_en.tsv from english folder\n",
            "✅ Successfully loaded dev_it.tsv from italian folder\n",
            "Training with 8926 examples\n",
            "Validating with 2393 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = {f: train_data[f] for f in train_files if f in train_data}\n",
        "for fname, df in train_files.items():\n",
        "    print(f\"{fname}: {df.shape}\")\n",
        "    print(df.head(2))"
      ],
      "metadata": {
        "id": "pwtKsB2d-_8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.tail(10))  # Show last 10 rows\n",
        "print(train_data.dtypes)     # Data types of each column\n",
        "print(train_data.columns)    # Column names\n",
        "print(train_data.shape)      # (rows, columns)\n",
        "print(train_data.tail(10).isnull().sum())  # NaNs in the last 10 rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq6tbBh14rnn",
        "outputId": "018071da-8edd-41e3-f135-602a17b4c7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               sentence_id  \\\n",
            "8916  9dc6b4dd-0370-4e70-8ff2-c17db43e1e1a   \n",
            "8917  2defaff4-710e-4c81-bd2e-0cdbc08327a7   \n",
            "8918  a0ceb734-05cb-4020-aeef-2d8bd3a5aae4   \n",
            "8919  d1c914b5-eb77-492d-8cbc-32c80bcda387   \n",
            "8920  595e2f97-ce1e-4694-ad38-eae671875d00   \n",
            "8921  0e93f441-9faa-4b64-ad38-690e86b1d0f7   \n",
            "8922  bdad5c4d-d160-4d8c-9e16-8f26512b8479   \n",
            "8923  3e6f5ca0-7cfe-4a3b-96b0-b00af2f9186f   \n",
            "8924  ddae1feb-9fb4-4574-828c-67fe8c3bb063   \n",
            "8925  5266c6a6-85d6-4ef4-b9dc-cf7987456398   \n",
            "\n",
            "                                               sentence label language  \\\n",
            "8916  Per questo è importante costruire una cabina d...   OBJ       it   \n",
            "8917  L'evoluzione di quest'oggi aggiunge un altro t...  SUBJ       it   \n",
            "8918  Dunque non ha escluso che Pfizer possa avere u...   OBJ       it   \n",
            "8919  22 persone sono state arrestate nell’ambito di...   OBJ       it   \n",
            "8920  Ogni singolo messaggio è stato inviato alla Po...   OBJ       it   \n",
            "8921   Presi due della banda, il più piccolo ha 15 anni   OBJ       it   \n",
            "8922  Il congresso è previsto tra due anni ma appena...  SUBJ       it   \n",
            "8923  Tutto ciò che fanno nasce da un amore sincero ...  SUBJ       it   \n",
            "8924  ha detto il segretario di Stato Usa Antony Bli...   OBJ       it   \n",
            "8925  I provvedimenti sono stati delegati dal sostit...   OBJ       it   \n",
            "\n",
            "      label_id  \n",
            "8916         0  \n",
            "8917         1  \n",
            "8918         0  \n",
            "8919         0  \n",
            "8920         0  \n",
            "8921         0  \n",
            "8922         1  \n",
            "8923         1  \n",
            "8924         0  \n",
            "8925         0  \n",
            "sentence_id    object\n",
            "sentence       object\n",
            "label          object\n",
            "language       object\n",
            "label_id        int64\n",
            "dtype: object\n",
            "Index(['sentence_id', 'sentence', 'label', 'language', 'label_id'], dtype='object')\n",
            "(8926, 5)\n",
            "sentence_id    0\n",
            "sentence       0\n",
            "label          0\n",
            "language       0\n",
            "label_id       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First few rows:\", train_data.iloc[:5])     # First few original rows\n",
        "print(\":====================================\")\n",
        "print(\"Last few rows: \", train_data.iloc[-5:])    # Last few (potentially augmented) rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc77_TdT56V4",
        "outputId": "6ce2014b-3782-4aa5-e74d-bc055c09f5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows:             sentence_id                                           sentence  \\\n",
            "0    AlMasryAlYoum_10_1  عندما تولى الرئيس عبد الفتاح السيسى السلطة فى ...   \n",
            "1    MAH_62-curl_01_005  في هذا السياق يشرح عيراني أنّ الخوف لا يقتصر ف...   \n",
            "2   MIS_676-eurl_02_015  وشكك المدير التنفيذي وعميد مجلس المديرين التنف...   \n",
            "3  MIS_2290-curl_03_018  ﻟﻜﻦ ﻟﻸﺳﻒ ﺍﻟﺮﺻﺎﺻﺔ ﻟﻢ ﺗﺼﺐ ﺃﻣﻪ ﻭ ﺍﺳﺘﻘﺮﺕ ﻓﻲ ﺭأﺱ  ر...   \n",
            "4   MIS_460-eurl_02_001  الوزارة طالبت بضرورة احترام الإجراءات الوقائية...   \n",
            "\n",
            "  label language  label_id  \n",
            "0   OBJ       ar         0  \n",
            "1   OBJ       ar         0  \n",
            "2   OBJ       ar         0  \n",
            "3   OBJ       ar         0  \n",
            "4   OBJ       ar         0  \n",
            ":====================================\n",
            "Last few rows:                                 sentence_id  \\\n",
            "8921  0e93f441-9faa-4b64-ad38-690e86b1d0f7   \n",
            "8922  bdad5c4d-d160-4d8c-9e16-8f26512b8479   \n",
            "8923  3e6f5ca0-7cfe-4a3b-96b0-b00af2f9186f   \n",
            "8924  ddae1feb-9fb4-4574-828c-67fe8c3bb063   \n",
            "8925  5266c6a6-85d6-4ef4-b9dc-cf7987456398   \n",
            "\n",
            "                                               sentence label language  \\\n",
            "8921   Presi due della banda, il più piccolo ha 15 anni   OBJ       it   \n",
            "8922  Il congresso è previsto tra due anni ma appena...  SUBJ       it   \n",
            "8923  Tutto ciò che fanno nasce da un amore sincero ...  SUBJ       it   \n",
            "8924  ha detto il segretario di Stato Usa Antony Bli...   OBJ       it   \n",
            "8925  I provvedimenti sono stati delegati dal sostit...   OBJ       it   \n",
            "\n",
            "      label_id  \n",
            "8921         0  \n",
            "8922         1  \n",
            "8923         1  \n",
            "8924         0  \n",
            "8925         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "with pd.option_context('display.max_rows', 10, 'display.max_columns', None, 'display.width', 1000):\n",
        "    print(train_data.tail(30))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2FXexd06akM",
        "outputId": "6520d6bb-7ea0-47af-c080-d2e258a37b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               sentence_id                                           sentence label language  label_id\n",
            "8896  eca73829-ad31-4b74-8412-6c466ea901e9  I tempi sono invece più lunghi per il prossimo...   OBJ       it         0\n",
            "8897  b79e9ad4-8989-43c1-b1fd-f348218319f5  Tra i settori in calo soprattutto gli autonomi...   OBJ       it         0\n",
            "8898  3c799a87-a5df-4eb6-95a7-dc7673ac7d27  Pfizer è pronta a far decollare verso tutti i ...   OBJ       it         0\n",
            "8899  d2850f01-e772-4248-8c6f-2e59ab0ca5fa   Creata nel 2013 da due neolaureati di Princet...   OBJ       it         0\n",
            "8900  ec8dcabb-3245-4601-8f4f-a31081cc45a6  Nuovo picco di ricoverati Covid in Umbria, ogg...   OBJ       it         0\n",
            "...                                    ...                                                ...   ...      ...       ...\n",
            "8921  0e93f441-9faa-4b64-ad38-690e86b1d0f7   Presi due della banda, il più piccolo ha 15 anni   OBJ       it         0\n",
            "8922  bdad5c4d-d160-4d8c-9e16-8f26512b8479  Il congresso è previsto tra due anni ma appena...  SUBJ       it         1\n",
            "8923  3e6f5ca0-7cfe-4a3b-96b0-b00af2f9186f  Tutto ciò che fanno nasce da un amore sincero ...  SUBJ       it         1\n",
            "8924  ddae1feb-9fb4-4574-828c-67fe8c3bb063  ha detto il segretario di Stato Usa Antony Bli...   OBJ       it         0\n",
            "8925  5266c6a6-85d6-4ef4-b9dc-cf7987456398  I provvedimenti sono stati delegati dal sostit...   OBJ       it         0\n",
            "\n",
            "[30 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the dataset"
      ],
      "metadata": {
        "id": "g9pAlpvzXNJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SubjectivityDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Dataset for subjectivity classification\n",
        "\n",
        "        Args:\n",
        "            dataframe: DataFrame containing text and labels\n",
        "            tokenizer: Tokenizer to use for encoding\n",
        "            max_length: Maximum sequence length\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe['sentence'].tolist()  # Adjust column name if needed\n",
        "\n",
        "        # Convert string labels to integers if needed\n",
        "        labels = dataframe['label'].tolist()  # Adjust column name if needed\n",
        "        self.targets = []\n",
        "\n",
        "\n",
        "\n",
        "        for label in labels:\n",
        "            if isinstance(label, str):\n",
        "                # Common string label conversions\n",
        "                if label.lower() in ['subj', \"SUBJ\"]: # Add your expected string labels for class 1\n",
        "                    self.targets.append(1)\n",
        "                elif label.lower() in ['obj', \"OBJ\"]: # Add your expected string labels for class 0\n",
        "                    self.targets.append(0)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown label: {label}\") # Raise an error for unexpected labels\n",
        "            else:\n",
        "                # If it's already an integer or float\n",
        "                self.targets.append(int(label))\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        target = self.targets[index]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(target, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "piWl9P4Cguzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code before training to inspect your data labels\n",
        "print(\"Inspecting train data...\")\n",
        "print(\"\\nLabel column name and first few values:\")\n",
        "for col in train_data.columns:\n",
        "    if 'label' in col.lower():\n",
        "        print(f\"Column: {col}\")\n",
        "        print(f\"Values: {train_data[col].head(5).tolist()}\")\n",
        "        print(f\"Type: {type(train_data[col].iloc[0])}\")\n",
        "\n",
        "print(\"\\nChecking for missing values:\")\n",
        "print(train_data.isnull().sum())\n",
        "\n",
        "print(\"\\nChecking data types:\")\n",
        "print(train_data.dtypes)\n",
        "\n",
        "print(\"\\nUnique labels:\")\n",
        "for col in train_data.columns:\n",
        "    if 'label' in col.lower():\n",
        "        print(f\"{col}: {train_data[col].unique()}\")\n",
        "\n",
        "# If needed, convert labels to integers\n",
        "if 'label' in train_data.columns and train_data['label'].dtype == 'object':\n",
        "    print(\"\\nConverting string labels to integers...\")\n",
        "    # Map function for label conversion - adjust based on your actual labels\n",
        "    def convert_label(label):\n",
        "        if isinstance(label, str):\n",
        "            if label.lower() in ['subjective', 'subj', 'positive', 'pos', 'yes', 'true', '1']:\n",
        "                return 1\n",
        "            else:\n",
        "                return 0\n",
        "        return int(label)\n",
        "\n",
        "    # Convert and show sample results\n",
        "    train_data['label'] = train_data['label'].apply(convert_label)\n",
        "    val_data['label'] = val_data['label'].apply(convert_label)\n",
        "\n",
        "    print(\"After conversion:\")\n",
        "    print(f\"Train labels: {train_data['label'].head(5).tolist()}\")\n",
        "    print(f\"Type: {type(train_data['label'].iloc[0])}\")\n",
        "    print(f\"Unique values: {train_data['label'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnSIG1Smj5tU",
        "outputId": "4ac47c30-f353-4e55-ea93-a8b613becbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting train data...\n",
            "\n",
            "Label column name and first few values:\n",
            "Column: label\n",
            "Values: ['OBJ', 'OBJ', 'OBJ', 'OBJ', 'OBJ']\n",
            "Type: <class 'str'>\n",
            "Column: label_id\n",
            "Values: [0, 0, 0, 0, 0]\n",
            "Type: <class 'numpy.int64'>\n",
            "\n",
            "Checking for missing values:\n",
            "sentence_id    0\n",
            "sentence       0\n",
            "label          0\n",
            "language       0\n",
            "label_id       0\n",
            "dtype: int64\n",
            "\n",
            "Checking data types:\n",
            "sentence_id    object\n",
            "sentence       object\n",
            "label          object\n",
            "language       object\n",
            "label_id        int64\n",
            "dtype: object\n",
            "\n",
            "Unique labels:\n",
            "label: ['OBJ' 'SUBJ']\n",
            "label_id: [0 1]\n",
            "\n",
            "Converting string labels to integers...\n",
            "After conversion:\n",
            "Train labels: [0, 0, 0, 0, 0]\n",
            "Type: <class 'numpy.int64'>\n",
            "Unique values: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "with pd.option_context('display.max_rows', 10, 'display.max_columns', None, 'display.width', 1000):\n",
        "    print(train_data.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP6r41u16yhe",
        "outputId": "af2aac95-a955-454b-980d-db689d94200f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            sentence_id                                           sentence  label language  label_id\n",
            "0    AlMasryAlYoum_10_1  عندما تولى الرئيس عبد الفتاح السيسى السلطة فى ...      0       ar         0\n",
            "1    MAH_62-curl_01_005  في هذا السياق يشرح عيراني أنّ الخوف لا يقتصر ف...      0       ar         0\n",
            "2   MIS_676-eurl_02_015  وشكك المدير التنفيذي وعميد مجلس المديرين التنف...      0       ar         0\n",
            "3  MIS_2290-curl_03_018  ﻟﻜﻦ ﻟﻸﺳﻒ ﺍﻟﺮﺻﺎﺻﺔ ﻟﻢ ﺗﺼﺐ ﺃﻣﻪ ﻭ ﺍﺳﺘﻘﺮﺕ ﻓﻲ ﺭأﺱ  ر...      0       ar         0\n",
            "4   MIS_460-eurl_02_001  الوزارة طالبت بضرورة احترام الإجراءات الوقائية...      0       ar         0\n",
            "5  MIS_1955-eurl_01_024  نحن نتحدث عن كيان صهيوني كل الناس يعرفون ماذا ...      1       ar         1\n",
            "6  MIS_2585-eurl_01_013  - اعرف مكان أقرب مخرج طوارئ، وعُدّ كم صفا من ا...      0       ar         0\n",
            "7  MIS_1466-eurl_04_011  تعرضت لضغوطات نفسية كثيرة أثناء جلسات التحقيق ...      0       ar         0\n",
            "8               AJ_2_12  وقالت أخرى: \"كنت هناك للتو، وفجأة حدث لي شيء ف...      1       ar         1\n",
            "9   MIS_191-curl_01_008  وأعلنت السلطات الصينية، اليوم الجمعة، ارتفاع ح...      1       ar         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.dtypes)     # Data types of each column\n",
        "print(train_data.columns)    # Column names\n",
        "print(train_data.shape)      # (rows, columns)\n",
        "\n",
        "print(train_data.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTG3CnKX7MYg",
        "outputId": "6c8bd960-cd82-48a4-9036-b411e0b9170f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_id    object\n",
            "sentence       object\n",
            "label           int64\n",
            "language       object\n",
            "label_id        int64\n",
            "dtype: object\n",
            "Index(['sentence_id', 'sentence', 'label', 'language', 'label_id'], dtype='object')\n",
            "(8926, 5)\n",
            "          sentence_id                                           sentence  \\\n",
            "0  AlMasryAlYoum_10_1  عندما تولى الرئيس عبد الفتاح السيسى السلطة فى ...   \n",
            "\n",
            "   label language  label_id  \n",
            "0      0       ar         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Compute evaluation metrics for model predictions\n",
        "\n",
        "    Args:\n",
        "        pred: Prediction object from Trainer\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing accuracy, F1 score, precision and recall\n",
        "    \"\"\"\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "ifiyiA7kf6_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "def train_model(train_dataset, val_dataset, BATCH_SIZE=4, LEARNING_RATE=2e-5, EPOCHS=3):\n",
        "    \"\"\"\n",
        "    Train the model using the provided datasets\n",
        "\n",
        "    Args:\n",
        "        train_dataset: Training dataset\n",
        "        val_dataset: Validation dataset\n",
        "        BATCH_SIZE: Batch size for training\n",
        "        LEARNING_RATE: Learning rate\n",
        "        EPOCHS: Number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        model: Trained model\n",
        "        trainer: Trainer object\n",
        "    \"\"\"\n",
        "    # Model name\n",
        "    MODEL_NAME = MODEL_NAME_\n",
        "\n",
        "    # Load model with config for binary classification\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=2,  # Binary classification\n",
        "        ignore_mismatched_sizes=True  # Handle potential mismatches\n",
        "    )\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "     # Replace 'evaluation_strategy' with 'eval_strategy'\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to='none'\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    eval_result = trainer.evaluate()\n",
        "    print(f\"Evaluation results: {eval_result}\")\n",
        "\n",
        "    return model, trainer"
      ],
      "metadata": {
        "id": "FfswUtHvf7Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 3. Set hyperparameters\n",
        "MAX_LENGTH = 64\n",
        "BATCH_SIZE = 4  # Consider reducing if you have memory issues\n",
        "LEARNING_RATE = 3e-5\n",
        "EPOCHS = 8\n",
        "\n"
      ],
      "metadata": {
        "id": "jPNB7LLEf7He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Load tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "MODEL_NAME = MODEL_NAME_\n",
        "print(f\"Loading tokenizer for {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "3e8058527bfb48b1ae2c9e029f05d289",
            "b5a5da7a9ee64910a736cce4d403cbfc",
            "0baea48fe94847b6a18ad93813f71595",
            "ab51e0c0780547878fa82bfb022a115b",
            "1dde81114662403692cb1367679cb4b0",
            "6a10e37125644d688f6066f28370ca59",
            "f5ffff70f3ff4e99b868039baa6838d1",
            "6b732679b15b49f3a5f1fdf6ffba98ff",
            "76500758050f4a64b4d3600e3a6ff978",
            "a2ec2c31302c43b4948d2bdef795240b",
            "159e4856f53049859726eafdb320fdc5",
            "3009f5b0d57847d0a8c3535d5e79b725",
            "e7ec28e0c3b54c1195f34e6166912732",
            "3501c5bf710742cc911275ba17aa0fdf",
            "63691d12aa264e07934a8d179d2ea013",
            "01be82b95fdd4732a6e62473c3562a18",
            "b2f84e8de73f42a4997a5a1e4a791c39",
            "ef17c62b7ef042c6a9ab015d9d38570d",
            "69e1492a16bd4aa5bfe0dc6342b5980a",
            "f9a341b156bc4670aa4312784ef8dbe8",
            "cadd21488f484883b9f5e8fec4bcb1c3",
            "192da315f59b4b05acb9fab8c344bbdc",
            "30ee32c158134dcbb2e6dbcaff99fd64",
            "51720de1de5e4bcaa5fc7c92a115ace8",
            "9867611161214c59b0df16fb224af2c5",
            "41509aa7a993401ab70a9fd2861efd77",
            "c91915a6d00c4de19cffc8c02c754218",
            "5bfd1c24c2834ee7aaf9b1cdde50b335",
            "b40215f1604b496db36e0cd3debdd85e",
            "6ecdd626f77f466291f4c6eef48e2464",
            "0b472b38d8454095be5a7497eb6ec344",
            "bbce2343f6d54b30bf45d401c6e24624",
            "c30181874a834f79bddf4182bd92c966",
            "9b95ad0ceae5490db4e5fba1ea757613",
            "02c9a4d02e6f46d8a6340803cf4b2ad7",
            "a72205ee67684ad9a67839b16871bd1d",
            "b16bf220fd9b4d799cc35c12250e8551",
            "73a00d53a0aa4ad99af1b715e640aaa0",
            "69a4cc6705ca4ca6b5077adaa7acff5f",
            "3a9b21bb7e9349868c5050801561246e",
            "c7cd77e2e0444890a60165d4792f09ac",
            "73e4e08b3e0549e6935ae75db4dc0151",
            "19a93821f7834e2fa1e13b027fd3cc26",
            "8d0bcc8b74a04a25aa22d68ac9ed8dfa",
            "58b3608e5662475dbceb276b4431e4ac",
            "2c7483c1881142c79af6e04ec081628f",
            "a20fe7923dc245ac8ee202b07bcddf0a",
            "a7762fbe39614ea598e60445435c2155",
            "61924113455c4205a3e90b020bb76ab3",
            "89b66a11ddc14257a9f54b2a2de91a5d",
            "e7efd86b94a446e890a23bd008e0b95f",
            "32bff2df40634429b32ca58ca32498a6",
            "dd356c67de39415f91ac41377976a4bd",
            "20100cf0f31d46ecb04ddcaffca40655",
            "739577decd024e92a5208e3b854312cf"
          ]
        },
        "id": "ngZCLnpBiaqi",
        "outputId": "a629844b-eae0-4bfe-cc85-5f219a8b81a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer for GroNLP/mdebertav3-subjectivity-multilingual...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/412 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e8058527bfb48b1ae2c9e029f05d289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3009f5b0d57847d0a8c3535d5e79b725"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30ee32c158134dcbb2e6dbcaff99fd64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b95ad0ceae5490db4e5fba1ea757613"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58b3608e5662475dbceb276b4431e4ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"sample\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-Gz5Dq3ioOL",
        "outputId": "f6817f3e-37e4-4710-fb8c-1402c4d2273d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1, 36850, 2], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create datasets\n",
        "print(\"Creating datasets...\")\n",
        "train_dataset = SubjectivityDataset(train_data, tokenizer, MAX_LENGTH)\n",
        "val_dataset = SubjectivityDataset(val_data, tokenizer, MAX_LENGTH)\n",
        "print(f\"Dataset creation complete. Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRE4a39PidKB",
        "outputId": "7c0248b5-646e-47e7-ab4e-3f961256f3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating datasets...\n",
            "Dataset creation complete. Train size: 8926, Validation size: 2393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train model\n",
        "print(\"Starting model training...\")\n",
        "model, trainer = train_model(\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    BATCH_SIZE=BATCH_SIZE,\n",
        "    LEARNING_RATE=LEARNING_RATE,\n",
        "    EPOCHS=EPOCHS\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training and evaluation complete!\")"
      ],
      "metadata": {
        "id": "xqPWVi5HibKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Set save path\n",
        "save_dir = '/content/drive/MyDrive/saved_model'\n",
        "\n",
        "# Save using trainer\n",
        "trainer.save_model(save_dir)         # Saves model, config, and tokenizer (if attached)\n",
        "tokenizer.save_pretrained(save_dir) # Save tokenizer separately if not already included\n",
        "\n",
        "print(f\"✅ Model and tokenizer saved to {save_dir}\")\n"
      ],
      "metadata": {
        "id": "n8GoB1_VH_fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for Loading the trained model"
      ],
      "metadata": {
        "id": "vn0B_5Vt_KYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "save_dir = '/content/drive/MyDrive/saved_model'\n",
        "# Load from the same path\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "\n",
        "# Move model to correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"✅ Model and tokenizer successfully loaded from Drive\")\n"
      ],
      "metadata": {
        "id": "NCokA0zSIBXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec48948-cf4c-4fd1-c1e1-28a19ff80e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer successfully loaded from Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKGMppZUOmW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the evaluation data"
      ],
      "metadata": {
        "id": "RDZeKv_eOnIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Language code to folder name mapping\n",
        "language_map = {\n",
        "    'ar': 'arabic',\n",
        "    'bg': 'bulgarian',\n",
        "    'de': 'german',\n",
        "    'en': 'english',\n",
        "    'it': 'italian'\n",
        "}\n",
        "\n",
        "# Copy dev_test and unlabeled test files for each language\n",
        "for lang_code, lang_name in language_map.items():\n",
        "    source_dir = f\"/content/drive/MyDrive/data/{lang_name}\"\n",
        "    target_dir = f\"/content/data/{lang_name}/eval\"\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # Define filenames\n",
        "    dev_test_file = f\"dev_test_{lang_code}.tsv\"\n",
        "    unlabeled_file = f\"test_{lang_code}_unlabeled.tsv\"\n",
        "\n",
        "    for file_name in [dev_test_file, unlabeled_file]:\n",
        "        source_file = os.path.join(source_dir, file_name)\n",
        "        target_file = os.path.join(target_dir, file_name)\n",
        "\n",
        "        if os.path.exists(source_file):\n",
        "            shutil.copy(source_file, target_file)\n",
        "            print(f\"✅ Copied {file_name} to {target_dir}\")\n",
        "        else:\n",
        "            print(f\"❌ File not found: {source_file}\")\n"
      ],
      "metadata": {
        "id": "zazYCjCaOmZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b691169-6450-4ba0-c7e1-9d28faa435e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Copied dev_test_ar.tsv to /content/data/arabic/eval\n",
            "✅ Copied test_ar_unlabeled.tsv to /content/data/arabic/eval\n",
            "✅ Copied dev_test_bg.tsv to /content/data/bulgarian/eval\n",
            "❌ File not found: /content/drive/MyDrive/data/bulgarian/test_bg_unlabeled.tsv\n",
            "✅ Copied dev_test_de.tsv to /content/data/german/eval\n",
            "✅ Copied test_de_unlabeled.tsv to /content/data/german/eval\n",
            "✅ Copied dev_test_en.tsv to /content/data/english/eval\n",
            "✅ Copied test_en_unlabeled.tsv to /content/data/english/eval\n",
            "✅ Copied dev_test_it.tsv to /content/data/italian/eval\n",
            "✅ Copied test_it_unlabeled.tsv to /content/data/italian/eval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Dataset class for test data\n",
        "class TestSubjectivityDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.data.iloc[idx]['sentence']\n",
        "        label = self.data.iloc[idx]['label_id']\n",
        "\n",
        "        # Tokenize the sentence\n",
        "        encoding = self.tokenizer(\n",
        "            sentence,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Remove the batch dimension\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "        # Add the label and sentence ID\n",
        "        encoding['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        encoding['sentence_idx'] = idx\n",
        "\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "5HQJ0vwfROwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just for testing predictions on all languages"
      ],
      "metadata": {
        "id": "uM1T5QTt9pCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import csv\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_on_test_set(test_file_path, model, tokenizer, max_length=128, batch_size=16):\n",
        "    # Load test data\n",
        "    test_data = pd.read_csv(test_file_path, sep='\\t')\n",
        "    print(f\"Loaded test data with {len(test_data)} examples\")\n",
        "    print(f\"Columns: {test_data.columns.tolist()}\")\n",
        "\n",
        "    # Map labels to IDs\n",
        "    test_data['label_id'] = test_data['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    test_dataset = TestSubjectivityDataset(test_data, tokenizer, max_length)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store results\n",
        "    all_predictions = []\n",
        "    all_pred_labels = []\n",
        "    all_true_labels = []\n",
        "    all_indices = []\n",
        "\n",
        "    # Perform predictions\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            # Get the sentence indices\n",
        "            indices = batch.pop('sentence_idx')\n",
        "\n",
        "            # Move batch to device\n",
        "            batch = {k: v.to(device) for k, v in batch.items() if k != 'sentence_idx'}\n",
        "\n",
        "            # Get predictions\n",
        "            outputs = model(**batch)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_pred_labels.extend(pred_classes.cpu().numpy())\n",
        "            all_true_labels.extend(batch['labels'].cpu().numpy())\n",
        "            all_indices.extend(indices.numpy())\n",
        "\n",
        "    # Convert to text labels\n",
        "    pred_text_labels = [\"OBJ\" if p == 0 else \"SUBJ\" for p in all_pred_labels]\n",
        "    true_text_labels = [\"OBJ\" if t == 0 else \"SUBJ\" for t in all_true_labels]\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame({\n",
        "        'sentence_id': [test_data.iloc[idx]['sentence_id'] for idx in all_indices],\n",
        "        'sentence': [test_data.iloc[idx]['sentence'] for idx in all_indices],\n",
        "        'label': pred_text_labels  # This is now 'label' as per required format\n",
        "    })\n",
        "\n",
        "    # Save predictions in format matching the evaluation script\n",
        "    output_path = f\"predictions_{test_file_path.split('/')[-1]}\"\n",
        "    results_df[['sentence_id', 'label']].to_csv(output_path, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
        "    print(f\"\\nPredictions saved to {output_path}\")\n",
        "\n",
        "    # Create a gold standard dataframe (for local evaluation)\n",
        "    gold_df = pd.DataFrame({\n",
        "        'sentence_id': [test_data.iloc[idx]['sentence_id'] for idx in all_indices],\n",
        "        'label': true_text_labels\n",
        "    })\n",
        "\n",
        "    # Calculate scores using the official evaluation function\n",
        "    whole_data = pd.DataFrame({\n",
        "        'sentence_id': results_df['sentence_id'],\n",
        "        'pred_label': results_df['label'],\n",
        "        'gold_label': gold_df['label']\n",
        "    })\n",
        "\n",
        "    # Calculate evaluation metrics matching the official script\n",
        "    pred_values = whole_data['pred_label'].values\n",
        "    gold_values = whole_data['gold_label'].values\n",
        "\n",
        "    acc = accuracy_score(gold_values, pred_values)\n",
        "    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, pred_values, average=\"macro\", zero_division=0)\n",
        "    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, pred_values, labels=[\"SUBJ\"], zero_division=0)\n",
        "\n",
        "    scores = {\n",
        "        'macro-F1': m_f1,\n",
        "        'macro-P': m_prec,\n",
        "        'macro-R': m_rec,\n",
        "        'SUBJ-F1': p_f1[0],\n",
        "        'SUBJ-P': p_prec[0],\n",
        "        'SUBJ-R': p_rec[0],\n",
        "        'accuracy': acc\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n===== Model Performance on {test_file_path} =====\")\n",
        "    print(f\"\"\"\n",
        "        macro-F1: {scores['macro-F1']:.4f}\n",
        "        macro-P: {scores['macro-P']:.4f}\n",
        "        macro-R: {scores['macro-R']:.4f}\n",
        "\n",
        "        SUBJ-F1: {scores['SUBJ-F1']:.4f}\n",
        "        SUBJ-P: {scores['SUBJ-P']:.4f}\n",
        "        SUBJ-R: {scores['SUBJ-R']:.4f}\n",
        "\n",
        "        accuracy: {scores['accuracy']:.4f}\n",
        "    \"\"\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(gold_values, pred_values, labels=[\"OBJ\", \"SUBJ\"])\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"              Predicted\")\n",
        "    print(\"             OBJ    SUBJ\")\n",
        "    print(f\"Actual OBJ  {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
        "    print(f\"      SUBJ  {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
        "\n",
        "    # Error analysis - find examples where model was wrong\n",
        "    errors_df = whole_data[whole_data['pred_label'] != whole_data['gold_label']]\n",
        "    if not errors_df.empty:\n",
        "        error_output_path = f\"errors_{test_file_path.split('/')[-1]}\"\n",
        "        # Join with original data to get sentences\n",
        "        error_data = pd.merge(errors_df, test_data[['sentence_id', 'sentence']], on='sentence_id')\n",
        "        error_data.to_csv(error_output_path, sep='\\t', index=False)\n",
        "        print(f\"Examples of misclassifications saved to {error_output_path}\")\n",
        "\n",
        "        # Print a few examples of misclassifications\n",
        "        print(\"\\nExamples of misclassifications:\")\n",
        "        sample_errors = error_data.sample(min(5, len(error_data)))\n",
        "        for _, row in sample_errors.iterrows():\n",
        "            print(f\"Sentence ID: {row['sentence_id']}\")\n",
        "            print(f\"Sentence: {row['sentence']}\")\n",
        "            print(f\"True: {row['gold_label']}, Predicted: {row['pred_label']}\")\n",
        "            print(\"\")\n",
        "\n",
        "    return results_df, scores"
      ],
      "metadata": {
        "id": "bTbzNRpisdib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Language code to folder name mapping\n",
        "language_map = {\n",
        "    'ar': 'arabic',\n",
        "    'bg': 'bulgarian',\n",
        "    'de': 'german',\n",
        "    'en': 'english',\n",
        "    'it': 'italian'\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "final = {}\n",
        "# Loop through each language and evaluate its test set\n",
        "for lang_code, lang_name in language_map.items():\n",
        "    test_file_name = f\"dev_test_{lang_code}.tsv\"\n",
        "    test_file_path = os.path.join(\"/content/data\", lang_name, \"eval\", test_file_name)\n",
        "\n",
        "    if os.path.exists(test_file_path):\n",
        "        print(f\"🔍 Evaluating on {test_file_name}...\")\n",
        "        results, metrics = evaluate_on_test_set(test_file_path, model, tokenizer)\n",
        "        final[lang_name] = metrics\n",
        "    else:\n",
        "        print(f\"❌ File not found: {test_file_path}\")\n",
        "\n",
        "print(\"\\n✅ Evaluation complete for all available test sets.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wW_GzA43f7J2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164a2195-45dc-4094-884a-66cc5b593e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Evaluating on dev_test_ar.tsv...\n",
            "Loaded test data with 748 examples\n",
            "Columns: ['sentence_id', 'sentence', 'label']\n",
            "\n",
            "Predictions saved to predictions_dev_test_ar.tsv\n",
            "\n",
            "===== Model Performance on /content/data/arabic/eval/dev_test_ar.tsv =====\n",
            "\n",
            "        macro-F1: 0.5222\n",
            "        macro-P: 0.5276\n",
            "        macro-R: 0.5280\n",
            "\n",
            "        SUBJ-F1: 0.5062\n",
            "        SUBJ-P: 0.4575\n",
            "        SUBJ-R: 0.5666\n",
            "\n",
            "        accuracy: 0.5227\n",
            "    \n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted\n",
            "             OBJ    SUBJ\n",
            "Actual OBJ   208    217\n",
            "      SUBJ   140    183\n",
            "Examples of misclassifications saved to errors_dev_test_ar.tsv\n",
            "\n",
            "Examples of misclassifications:\n",
            "Sentence ID: MIS_1617-eurl_02_004\n",
            "Sentence: وطمأن الشاب الجميع بأنه لا يوجد مصابين عرب أخرين في ووهان غيره، وعن المرض قال : “هذا المرض سهل ممتنع ويكاد يشبه الإنفولنزا ولكن بأكثر حدة وألم”، قائلا : “الأعراض صعبة ومؤلمة.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: MIS_195-eurl_05_009\n",
            "Sentence: مع أخذ ذلك في الاعتبار، أعلن ولي العهد، محمد بن سلمان، في عام 2017 عن رؤية السعودية 2030، وهو أكثر إصلاح جذري يمر به الاقتصاد السعودي حتى الآن.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: Almayadeen_5_60\n",
            "Sentence: - اختطاف وإعدام المفكر والمناضل المغربي المهدي بن بركة في باريس 1965، بمشاركة جهات استخبارية عديدة، منها جهات أوروبية وصهيونية وأميركية وعربية.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: AJ_8_12\n",
            "Sentence: لكن ما نشهده من صمود وغَلَبَة للمقاومة في الميدان في غزة، وتمسك بالأرض وتراب الوطن من جانب المواطنين، ورفض لأي تهجير قسري أو طوعي – رغم استشهاد وإصابة قرابة مئة ألف أو يزيدون حتى الآن- يجعل من \"طوفان الأقصى\" هزيمة إستراتيجية للغرب، كما هي لإسرائيل.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: MAH_62-curl_01_028\n",
            "Sentence: عيراني بشرب الشاي الأخضر والأسود بين الوجبات مع إضافة العقدة الصفراء، كونهما يحتويان على مادة theaflavin، وقد تبّين أنّها مهمة في تقوية جهاز المناعة، ومحاربة الخلايا السرطانية.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "🔍 Evaluating on dev_test_bg.tsv...\n",
            "Loaded test data with 250 examples\n",
            "Columns: ['sentence_id', 'sentence', 'label']\n",
            "\n",
            "Predictions saved to predictions_dev_test_bg.tsv\n",
            "\n",
            "===== Model Performance on /content/data/bulgarian/eval/dev_test_bg.tsv =====\n",
            "\n",
            "        macro-F1: 0.7424\n",
            "        macro-P: 0.7427\n",
            "        macro-R: 0.7421\n",
            "\n",
            "        SUBJ-F1: 0.7042\n",
            "        SUBJ-P: 0.7075\n",
            "        SUBJ-R: 0.7009\n",
            "\n",
            "        accuracy: 0.7480\n",
            "    \n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted\n",
            "             OBJ    SUBJ\n",
            "Actual OBJ   112     31\n",
            "      SUBJ    32     75\n",
            "Examples of misclassifications saved to errors_dev_test_bg.tsv\n",
            "\n",
            "Examples of misclassifications:\n",
            "Sentence ID: 8974a53b-0621-43c2-9088-713aea772ed7\n",
            "Sentence: Тъгата тук варира от помръкнало синьо до помпозно , позитанско червено.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: 11dbceca-c937-4d60-8c23-65cbdfeb488d\n",
            "Sentence: Така и става – и до днес Лили Иванова признава, а и показва недвусмислено, че не би заменила родината си за никоя друга.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 87a550c1-836d-4115-9fc5-8cd31a86212b\n",
            "Sentence: Как се промени образът на Тръмп в Русия след ударите в Сирия и виждате ли знаци, че нормализация на отношенията между Вашингтон и Кремъл все пак е възможна?\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 9bb54fcc-04a3-4232-9117-0234b9a1029a\n",
            "Sentence: Следователно Третата световна война в известен смисъл ще бъде директно насочена срещу него.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 5b92c04f-3d0d-4a7a-8367-07c838dd6a45\n",
            "Sentence: Имате мюсюлмански произход и без значение от религията, която изповядвате, на коя страна сте повече – на страната на женската еманципация и свободно право на избор, или по-скоро на строгите канони на вярата и законите на религията?\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "🔍 Evaluating on dev_test_de.tsv...\n",
            "Loaded test data with 224 examples\n",
            "Columns: ['sentence_id', 'sentence', 'label']\n",
            "\n",
            "Predictions saved to predictions_dev_test_de.tsv\n",
            "\n",
            "===== Model Performance on /content/data/german/eval/dev_test_de.tsv =====\n",
            "\n",
            "        macro-F1: 0.8525\n",
            "        macro-P: 0.8418\n",
            "        macro-R: 0.8718\n",
            "\n",
            "        SUBJ-F1: 0.8077\n",
            "        SUBJ-P: 0.7412\n",
            "        SUBJ-R: 0.8873\n",
            "\n",
            "        accuracy: 0.8661\n",
            "    \n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted\n",
            "             OBJ    SUBJ\n",
            "Actual OBJ   131     22\n",
            "      SUBJ     8     63\n",
            "Examples of misclassifications saved to errors_dev_test_de.tsv\n",
            "\n",
            "Examples of misclassifications:\n",
            "Sentence ID: ef3624e9a5d1f18cc2df6fc4acfa257b619c3268\n",
            "Sentence: Offensichtlich zeigte sich der russische Präsident alles andere als beeindruckt von den Argumenten, die Fortow vorbrachte.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 59ec56c9a629800130ebca692644bcd3e041366c\n",
            "Sentence: Wir gehen davon aus das die Dunkelziffer weit höher sein wird.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: 59e940af9a4323c930931d796193df774d29fdfc\n",
            "Sentence: RT-PCR kann SARS-CoV-2 nicht sicher feststellen: Explosive Studie zerstört Corman-Drosten-Paper\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: d066167a2289e1bf24f4c76bf6f81adb3f29d535\n",
            "Sentence: Vielleicht ein Grund, warum Influenza ausgestorben scheint?\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 6e8b732945b2884027671202d470b7d8a593a8b6\n",
            "Sentence: Und dies sind zu ganz überwiegenden Teilen keine Steuerzahler, sondern Leute, die von Steuergeldern leben, Menschen, die Steuergelber erhalten.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "🔍 Evaluating on dev_test_en.tsv...\n",
            "Loaded test data with 484 examples\n",
            "Columns: ['sentence_id', 'sentence', 'label']\n",
            "\n",
            "Predictions saved to predictions_dev_test_en.tsv\n",
            "\n",
            "===== Model Performance on /content/data/english/eval/dev_test_en.tsv =====\n",
            "\n",
            "        macro-F1: 0.7278\n",
            "        macro-P: 0.7225\n",
            "        macro-R: 0.7341\n",
            "\n",
            "        SUBJ-F1: 0.5984\n",
            "        SUBJ-P: 0.5758\n",
            "        SUBJ-R: 0.6230\n",
            "\n",
            "        accuracy: 0.7893\n",
            "    \n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted\n",
            "             OBJ    SUBJ\n",
            "Actual OBJ   306     56\n",
            "      SUBJ    46     76\n",
            "Examples of misclassifications saved to errors_dev_test_en.tsv\n",
            "\n",
            "Examples of misclassifications:\n",
            "Sentence ID: 68427b36-1420-4048-802b-12904e1fae8b\n",
            "Sentence: Later in a campaign speech, Trump rattled American allies in Europe when he claimed that he would encourage Russia to attack Nato allies who did not pay enough to maintain the security alliance.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: 149188c9-ac1c-47ef-998d-a67714b0243d\n",
            "Sentence: Brunero agrees that you have to expect the unexpected: her grandmother might be in her nineties but she’s in better shape than younger family members and has a way of getting her to open up about her life.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: ab4a9eea-ab03-403b-9526-187c3e614f36\n",
            "Sentence: House Democrats and the remaining pro-Ukraine House Republicans are casting about behind the scenes for a solution.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: 543fa891-6134-4e84-a71b-1c2c03fd510c\n",
            "Sentence: “American assistance with these efforts is not charity.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: a90dc760-a0fa-4ad1-ab79-2caa73874774\n",
            "Sentence: I just thought the prize was more than what I ended up with.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "🔍 Evaluating on dev_test_it.tsv...\n",
            "Loaded test data with 462 examples\n",
            "Columns: ['sentence_id', 'sentence', 'label']\n",
            "\n",
            "Predictions saved to predictions_dev_test_it.tsv\n",
            "\n",
            "===== Model Performance on /content/data/italian/eval/dev_test_it.tsv =====\n",
            "\n",
            "        macro-F1: 0.7588\n",
            "        macro-P: 0.7750\n",
            "        macro-R: 0.7475\n",
            "\n",
            "        SUBJ-F1: 0.6414\n",
            "        SUBJ-P: 0.6972\n",
            "        SUBJ-R: 0.5938\n",
            "\n",
            "        accuracy: 0.8160\n",
            "    \n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted\n",
            "             OBJ    SUBJ\n",
            "Actual OBJ   301     33\n",
            "      SUBJ    52     76\n",
            "Examples of misclassifications saved to errors_dev_test_it.tsv\n",
            "\n",
            "Examples of misclassifications:\n",
            "Sentence ID: ed87d697-774a-4986-9ee5-343aa800a207\n",
            "Sentence: La Meloni o la Schlein che decidono le politiche del Mezzogiorno? Ma siamo pazzi?“.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 4973c4ce-fd9f-493c-8007-bab14289b8a3\n",
            "Sentence: In quanto non tutti sono disposti a perdere una paziente, anche se è una paziente con cui non hanno feeling e armonia di vedute.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: dc1e4ddf-21f4-4fd8-a01c-4dfce9fda2f2\n",
            "Sentence: Il secondo è relativo alla legge Bersani che ha consentito una pubblicità scriteriata.\n",
            "True: SUBJ, Predicted: OBJ\n",
            "\n",
            "Sentence ID: 2307d140-930f-4a65-bc7b-db704a58c8ea\n",
            "Sentence: E se le aspettative non vengono soddisfatte, anche se l’intervento è tecnicamente corretto, il nostro obbiettivo, cioè il benessere del paziente, non sarà raggiunto.\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "Sentence ID: 2ef27aad-facf-4471-a74d-5ab920c7b64b\n",
            "Sentence: Russia, aperta un’inchiesta per terrorismo sull’aereo precipitato\n",
            "True: OBJ, Predicted: SUBJ\n",
            "\n",
            "\n",
            "✅ Evaluation complete for all available test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lang, data in final.items():\n",
        "  print(\"Language:\", lang, \" has metrics \", data)\n",
        "  print(\":======================================:\")"
      ],
      "metadata": {
        "id": "vPg6Wii4aMlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b296433-9176-4f8a-c27a-73080c4741c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language: arabic  has metrics  {'macro-F1': 0.5221935338418513, 'macro-P': 0.5276005747126438, 'macro-R': 0.5279876160990712, 'SUBJ-F1': np.float64(0.5062240663900415), 'SUBJ-P': np.float64(0.4575), 'SUBJ-R': np.float64(0.56656346749226), 'accuracy': 0.5227272727272727}\n",
            ":======================================:\n",
            "Language: bulgarian  has metrics  {'macro-F1': 0.7423565784953624, 'macro-P': 0.7426624737945493, 'macro-R': 0.7420756813280178, 'SUBJ-F1': np.float64(0.704225352112676), 'SUBJ-P': np.float64(0.7075471698113207), 'SUBJ-R': np.float64(0.7009345794392523), 'accuracy': 0.748}\n",
            ":======================================:\n",
            "Language: german  has metrics  {'macro-F1': 0.8524762908324552, 'macro-P': 0.8418112568768514, 'macro-R': 0.8717665469943846, 'SUBJ-F1': np.float64(0.8076923076923077), 'SUBJ-P': np.float64(0.7411764705882353), 'SUBJ-R': np.float64(0.8873239436619719), 'accuracy': 0.8660714285714286}\n",
            ":======================================:\n",
            "Language: english  has metrics  {'macro-F1': 0.7277840269966254, 'macro-P': 0.7225378787878788, 'macro-R': 0.734127343537723, 'SUBJ-F1': np.float64(0.5984251968503937), 'SUBJ-P': np.float64(0.5757575757575758), 'SUBJ-R': np.float64(0.6229508196721312), 'accuracy': 0.7892561983471075}\n",
            ":======================================:\n",
            "Language: italian  has metrics  {'macro-F1': 0.7588119322683471, 'macro-P': 0.7749694622761649, 'macro-R': 0.7474738023952097, 'SUBJ-F1': np.float64(0.6413502109704642), 'SUBJ-P': np.float64(0.6972477064220184), 'SUBJ-R': np.float64(0.59375), 'accuracy': 0.816017316017316}\n",
            ":======================================:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction on Multilingual Dataset (unlabelled)"
      ],
      "metadata": {
        "id": "Az08BZNl-hJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def predict_on_unlabelled(file_path, model, tokenizer, device, max_length=256, batch_size=16, output_path=None):\n",
        "    \"\"\"\n",
        "    Predict labels for unlabelled TSV file and save in format ready for evaluation.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the unlabelled TSV file.\n",
        "        model: Trained transformer model.\n",
        "        tokenizer: Associated tokenizer.\n",
        "        device: CUDA or CPU.\n",
        "        max_length (int): Max token length for each input.\n",
        "        batch_size (int): Batch size for inference.\n",
        "        output_path (str, optional): Path to save predictions. If None, uses \"predictions_[filename]\".\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with sentence_id and label columns.\n",
        "    \"\"\"\n",
        "    # Read the unlabelled data\n",
        "    df = pd.read_csv(file_path, sep='\\t', quoting=csv.QUOTE_NONE)\n",
        "\n",
        "    # Check required columns\n",
        "    if 'sentence' in df.columns:\n",
        "        raise ValueError(f\" 'sentence' column found in {file_path}\")\n",
        "    if 'sentence_id' not in df.columns:\n",
        "        raise ValueError(f\"No 'sentence_id' column found in {file_path}\")\n",
        "\n",
        "    # Prepare data\n",
        "    texts = df['sentence'].tolist()\n",
        "    sentence_ids = df['sentence_id'].tolist()\n",
        "    predictions = []\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Make predictions in batches\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=f\"Predicting {os.path.basename(file_path)}\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            encoded = tokenizer(batch_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "            encoded = {k: v.to(device) for k, v in encoded.items()}\n",
        "\n",
        "            outputs = model(**encoded)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Convert numeric predictions to text labels\n",
        "    label_map = {0: \"OBJ\", 1: \"SUBJ\"}\n",
        "    text_predictions = [label_map[pred] for pred in predictions]\n",
        "\n",
        "    # Create results dataframe with required columns\n",
        "    results_df = pd.DataFrame({\n",
        "        'sentence_id': sentence_ids,\n",
        "        'label': text_predictions\n",
        "    })\n",
        "\n",
        "    # Save predictions in required format\n",
        "    if output_path is None:\n",
        "        output_path = f\"predictions_{os.path.basename(file_path)}\"\n",
        "\n",
        "    results_df.to_csv(output_path, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
        "    print(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "kdSJQDEJeQH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import csv\n",
        "import zipfile\n",
        "from google.colab import files  # For downloading in Colab\n",
        "\n",
        "# Define the unlabelled test file and setting\n",
        "unlabelled_test_file = \"test_multilingual_unlabeled\"\n",
        "setting = \"multilingual\"\n",
        "\n",
        "# Set directories\n",
        "data_dir = \"/content/drive/MyDrive/data/multilingual\"\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "# Make sure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define input and output paths\n",
        "input_path = os.path.join(data_dir, f\"{unlabelled_test_file}.tsv\")\n",
        "output_file_name = f\"task1_test_{setting}.tsv\"\n",
        "output_path = os.path.join(output_dir, output_file_name)\n",
        "\n",
        "# Run predictions\n",
        "if os.path.exists(input_path):\n",
        "    print(f\"🔍 Predicting on {unlabelled_test_file}.tsv...\")\n",
        "\n",
        "    # Call the predict_on_unlabelled function with the output path\n",
        "    predict_on_unlabelled(\n",
        "        file_path=input_path,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device,\n",
        "        output_path=output_path\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Predictions saved to {output_path}\")\n",
        "\n",
        "    # Zip the TSV file\n",
        "    zip_path = os.path.join(output_dir, f\"task1_test_{setting}.zip\")\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        zipf.write(output_path, output_file_name)  # Add TSV to ZIP with just the file name\n",
        "\n",
        "    print(f\"📦 Zipped to {zip_path}\")\n",
        "\n",
        "    # Download the ZIP file\n",
        "    files.download(zip_path)\n",
        "else:\n",
        "    print(f\"❌ File not found: {input_path}\")\n",
        "\n",
        "print(\"📊 Prediction and zipping completed!\")"
      ],
      "metadata": {
        "id": "6-aQdh7feQKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SD0waTi3_gcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_subjectivity(model, tokenizer, sentences):\n",
        "    # Tokenize sentences\n",
        "    inputs = tokenizer(\n",
        "        sentences,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Get predictions\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Convert predictions to \"OBJ\" or \"SUBJ\"\n",
        "    prediction_labels = [\"OBJ\" if p == 0 else \"SUBJ\" for p in predictions.cpu().numpy()]\n",
        "\n",
        "    return prediction_labels"
      ],
      "metadata": {
        "id": "95aGQAgF_oxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Dataset class for test data\n",
        "class TestSubjectivityDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.data.iloc[idx]['sentence']\n",
        "        label = self.data.iloc[idx]['label_id']\n",
        "\n",
        "        # Tokenize the sentence\n",
        "        encoding = self.tokenizer(\n",
        "            sentence,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Remove the batch dimension\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "        # Add the label and sentence ID\n",
        "        encoding['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        encoding['sentence_idx'] = idx\n",
        "\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "gYxsPAzg_rqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_set(test_file_path, model, tokenizer, max_length=128, batch_size=16):\n",
        "    # Load test data\n",
        "    test_data = pd.read_csv(test_file_path, sep='\\t')\n",
        "    print(f\"Loaded test data with {len(test_data)} examples\")\n",
        "    print(f\"Columns: {test_data.columns.tolist()}\")\n",
        "\n",
        "    # Map labels to IDs\n",
        "    test_data['label_id'] = test_data['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    test_dataset = TestSubjectivityDataset(test_data, tokenizer, max_length)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store results\n",
        "    all_predictions = []\n",
        "    all_pred_labels = []\n",
        "    all_true_labels = []\n",
        "    all_indices = []\n",
        "\n",
        "    # Perform predictions\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            # Get the sentence indices\n",
        "            indices = batch.pop('sentence_idx')\n",
        "\n",
        "            # Move batch to device\n",
        "            batch = {k: v.to(device) for k, v in batch.items() if k != 'sentence_idx'}\n",
        "\n",
        "            # Get predictions\n",
        "            outputs = model(**batch)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_pred_labels.extend(pred_classes.cpu().numpy())\n",
        "            all_true_labels.extend(batch['labels'].cpu().numpy())\n",
        "            all_indices.extend(indices.numpy())\n",
        "\n",
        "    # Convert to text labels\n",
        "    pred_text_labels = [\"OBJ\" if p == 0 else \"SUBJ\" for p in all_pred_labels]\n",
        "    true_text_labels = [\"OBJ\" if t == 0 else \"SUBJ\" for t in all_true_labels]\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame({\n",
        "        'sentence_id': [test_data.iloc[idx]['sentence_id'] for idx in all_indices],\n",
        "        'sentence': [test_data.iloc[idx]['sentence'] for idx in all_indices],\n",
        "        'true_label': true_text_labels,\n",
        "        'predicted_label': pred_text_labels,\n",
        "        'obj_score': [round(p[0], 4) for p in all_predictions],\n",
        "        'subj_score': [round(p[1], 4) for p in all_predictions],\n",
        "    })\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_true_labels, all_pred_labels)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_true_labels, all_pred_labels, average='weighted'\n",
        "    )\n",
        "\n",
        "    # Detailed report\n",
        "    class_report = classification_report(all_true_labels, all_pred_labels,\n",
        "                                         target_names=['OBJ', 'SUBJ'], output_dict=True)\n",
        "\n",
        "    # Print detailed metrics\n",
        "    print(f\"\\n===== Model Performance on {test_file_path} =====\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score (weighted): {f1:.4f}\")\n",
        "    print(f\"Precision (weighted): {precision:.4f}\")\n",
        "    print(f\"Recall (weighted): {recall:.4f}\\n\")\n",
        "\n",
        "    # Print per-class metrics\n",
        "    print(\"Class-wise Performance:\")\n",
        "    print(f\"OBJ - Precision: {class_report['OBJ']['precision']:.4f}, \"\n",
        "          f\"Recall: {class_report['OBJ']['recall']:.4f}, \"\n",
        "          f\"F1: {class_report['OBJ']['f1-score']:.4f}\")\n",
        "    print(f\"SUBJ - Precision: {class_report['SUBJ']['precision']:.4f}, \"\n",
        "          f\"Recall: {class_report['SUBJ']['recall']:.4f}, \"\n",
        "          f\"F1: {class_report['SUBJ']['f1-score']:.4f}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"              Predicted\")\n",
        "    print(\"             OBJ    SUBJ\")\n",
        "    print(f\"Actual OBJ  {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
        "    print(f\"      SUBJ  {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
        "\n",
        "    # Save results\n",
        "    output_path = f\"predictions_{test_file_path.split('/')[-1]}\"\n",
        "    results_df.to_csv(output_path, sep='\\t', index=False)\n",
        "    print(f\"\\nDetailed predictions saved to {output_path}\")\n",
        "\n",
        "    # Error analysis - find examples where model was wrong\n",
        "    errors_df = results_df[results_df['true_label'] != results_df['predicted_label']]\n",
        "    if not errors_df.empty:\n",
        "        error_output_path = f\"errors_{test_file_path.split('/')[-1]}\"\n",
        "        errors_df.to_csv(error_output_path, sep='\\t', index=False)\n",
        "        print(f\"Examples of misclassifications saved to {error_output_path}\")\n",
        "\n",
        "        # Print a few examples of misclassifications\n",
        "        print(\"\\nExamples of misclassifications:\")\n",
        "        sample_errors = errors_df.sample(min(5, len(errors_df)))\n",
        "        for _, row in sample_errors.iterrows():\n",
        "            print(f\"Sentence ID: {row['sentence_id']}\")\n",
        "            print(f\"Sentence: {row['sentence']}\")\n",
        "            print(f\"True: {row['true_label']}, Predicted: {row['predicted_label']}\")\n",
        "            print(f\"Confidence scores - OBJ: {row['obj_score']}, SUBJ: {row['subj_score']}\")\n",
        "            print(\"\")\n",
        "\n",
        "    return results_df, {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'class_report': class_report\n",
        "    }"
      ],
      "metadata": {
        "id": "NjWpEpLA_tEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train the model\n",
        "# model, tokenizer = train_multilingual_subjectivity_classifier()"
      ],
      "metadata": {
        "id": "arFDvwfC_0Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "\n",
        "# data_dir = \"/content/drive/MyDrive/data/multilingual\"\n",
        "# output_dir = \"/content/output\"\n",
        "\n",
        "\n",
        "# language_map = {\n",
        "#         'ar': 'arabic',\n",
        "#         'bg': 'bulgarian',\n",
        "#         'de': 'german',\n",
        "#         'en': 'english',\n",
        "#         'it': 'italian'\n",
        "# }\n",
        "\n",
        "# test_list = [\"dev_test_it.tsv\", \"dev_test_en.tsv\", \"dev_test_de.tsv\", \"dev_test_ar.tsv\", \"dev_test_bg.tsv\"]\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# for test_file in test_list:\n",
        "#     test_file_p = test_file.split(\"_\")[-1].split(\".\")[0]\n",
        "#     test_file_path = os.path.join(data_dir, language_map[test_file_p], \"eval\", test_file)\n",
        "#     print(f\"Evaluating on {test_file_path}...\")\n",
        "#     results, metrics = evaluate_on_test_set(test_file, model, tokenizer)\n",
        "\n",
        "# # If you want to further analyze per-language performance, you can add that logic here\n",
        "# print(\"\\nEvaluation complete!\")"
      ],
      "metadata": {
        "id": "2Pewbv4G_45y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save to Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the save path\n",
        "# save_directory = \"/content/drive/MyDrive/multilingual-subjectivity-classifier-model\"\n",
        "\n",
        "# # Save model and tokenizer\n",
        "# model.save_pretrained(save_directory)\n",
        "# tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "# print(f\"Model successfully saved to {save_directory}\")"
      ],
      "metadata": {
        "id": "QJHedfzeFVqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction on unlabelled dataset (Zero Shot)"
      ],
      "metadata": {
        "id": "HTSCVx1R7Beg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define dataset class for unlabelled data\n",
        "class UnlabelledDataset(Dataset):\n",
        "        def __init__(self, data, tokenizer, max_length):\n",
        "            self.data = data\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.data)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            sentence = self.data.iloc[idx]['sentence']\n",
        "            sentence_id = self.data.iloc[idx]['sentence_id'] if 'sentence_id' in self.data.columns else idx\n",
        "\n",
        "            encoding = self.tokenizer(\n",
        "                sentence,\n",
        "                max_length=self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Remove batch dimension\n",
        "            encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "            # Add sentence index for tracking\n",
        "            encoding['sentence_idx'] = torch.tensor(idx)\n",
        "\n",
        "            return encoding"
      ],
      "metadata": {
        "id": "aefzBASG7JS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_unlabelled(data_file_path, model, tokenizer, max_length=128, batch_size=16):\n",
        "    \"\"\"\n",
        "    Run predictions on unlabelled data and save the results.\n",
        "\n",
        "    Args:\n",
        "        data_file_path: Path to the unlabelled data file (CSV/TSV)\n",
        "        model: The trained model\n",
        "        tokenizer: Tokenizer for the model\n",
        "        max_length: Maximum sequence length\n",
        "        batch_size: Batch size for inference\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with predictions\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Get device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load data\n",
        "    try:\n",
        "        # Try with tab separator first\n",
        "        data = pd.read_csv(data_file_path, sep='\\t')\n",
        "    except:\n",
        "        # Fall back to comma separator\n",
        "        data = pd.read_csv(data_file_path)\n",
        "\n",
        "    print(f\"Loaded data with {len(data)} examples\")\n",
        "    print(f\"Columns: {data.columns.tolist()}\")\n",
        "\n",
        "    # Ensure 'sentence' column exists\n",
        "    if 'sentence' not in data.columns:\n",
        "        raise ValueError(\"Data must contain a 'sentence' column\")\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = UnlabelledDataset(data, tokenizer, max_length)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store results\n",
        "    all_predictions = []\n",
        "    all_pred_labels = []\n",
        "    all_indices = []\n",
        "\n",
        "    # Perform predictions\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            # Get the sentence indices\n",
        "            indices = batch.pop('sentence_idx')\n",
        "\n",
        "            # Move batch to device\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # Get predictions\n",
        "            outputs = model(**batch)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_pred_labels.extend(pred_classes.cpu().numpy())\n",
        "            all_indices.extend(indices.numpy())\n",
        "\n",
        "    # Convert to text labels\n",
        "    pred_text_labels = [\"OBJ\" if p == 0 else \"SUBJ\" for p in all_pred_labels]\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame({\n",
        "        'sentence_id': [data.iloc[idx]['sentence_id'] for idx in all_indices],\n",
        "        'label': pred_text_labels,\n",
        "\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Save results\n",
        "    output_path = f\"predictions_{data_file_path.split('/')[-1]}\"\n",
        "    results_df.to_csv(output_path, sep='\\t', index=False)\n",
        "    print(f\"\\nPredictions saved to {output_path}\")\n",
        "\n",
        "    # Print distribution of predictions\n",
        "    obj_count = sum(1 for label in pred_text_labels if label == \"OBJ\")\n",
        "    subj_count = sum(1 for label in pred_text_labels if label == \"SUBJ\")\n",
        "    total = len(pred_text_labels)\n",
        "\n",
        "    print(\"\\nPrediction Distribution:\")\n",
        "    print(f\"OBJ: {obj_count} ({obj_count/total:.2%})\")\n",
        "    print(f\"SUBJ: {subj_count} ({subj_count/total:.2%})\")\n",
        "\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "kCbx_vTJ7Do3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/data/\"\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "\n",
        "language_map = {\n",
        "        'pol': 'polish',\n",
        "        'ukr': 'ukrainian',\n",
        "        'ro': 'romanian',\n",
        "        'gr' : 'greek'\n",
        "}\n",
        "\n",
        "test_list = [\"test_pol_unlabeled.tsv\", \"test_ukr_unlabeled.tsv\", \"test_ro_unlabeled.tsv\", \"test_gr_unlabeled.tsv\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "for test_file in test_list:\n",
        "    test_file_p = test_file.split(\"_\")[1].strip()\n",
        "    test_file_path = os.path.join(data_dir, language_map[test_file_p], test_file)\n",
        "    print(f\"Evaluating on {test_file_path}...\")\n",
        "    results = predict_on_unlabelled(test_file_path, model, tokenizer)\n",
        "\n",
        "# If you want to further analyze per-language performance, you can add that logic here\n",
        "print(\"\\nEvaluation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVsRTLsx7D-I",
        "outputId": "b1270ee5-982a-48a8-e274-d8ed629605b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on /content/drive/MyDrive/data/polish/test_pol_unlabeled.tsv...\n",
            "Using device: cuda\n",
            "Loaded data with 351 examples\n",
            "Columns: ['sentence_id', 'sentence']\n",
            "\n",
            "Predictions saved to predictions_test_pol_unlabeled.tsv\n",
            "\n",
            "Prediction Distribution:\n",
            "OBJ: 296 (84.33%)\n",
            "SUBJ: 55 (15.67%)\n",
            "Evaluating on /content/drive/MyDrive/data/ukrainian/test_ukr_unlabeled.tsv...\n",
            "Using device: cuda\n",
            "Loaded data with 297 examples\n",
            "Columns: ['sentence_id', 'sentence']\n",
            "\n",
            "Predictions saved to predictions_test_ukr_unlabeled.tsv\n",
            "\n",
            "Prediction Distribution:\n",
            "OBJ: 195 (65.66%)\n",
            "SUBJ: 102 (34.34%)\n",
            "Evaluating on /content/drive/MyDrive/data/romanian/test_ro_unlabeled.tsv...\n",
            "Using device: cuda\n",
            "Loaded data with 206 examples\n",
            "Columns: ['sentence_id', 'sentence']\n",
            "\n",
            "Predictions saved to predictions_test_ro_unlabeled.tsv\n",
            "\n",
            "Prediction Distribution:\n",
            "OBJ: 137 (66.50%)\n",
            "SUBJ: 69 (33.50%)\n",
            "Evaluating on /content/drive/MyDrive/data/greek/test_gr_unlabeled.tsv...\n",
            "Using device: cuda\n",
            "Loaded data with 284 examples\n",
            "Columns: ['sentence_id', 'sentence']\n",
            "\n",
            "Predictions saved to predictions_test_gr_unlabeled.tsv\n",
            "\n",
            "Prediction Distribution:\n",
            "OBJ: 240 (84.51%)\n",
            "SUBJ: 44 (15.49%)\n",
            "\n",
            "Evaluation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wythwh5Z_4i1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}